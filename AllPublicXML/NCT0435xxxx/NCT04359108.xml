<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on July 28, 2020</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT04359108</url>
  </required_header>
  <id_info>
    <org_study_id>IRB00228932</org_study_id>
    <secondary_id>1R01EY029741-01A1</secondary_id>
    <nct_id>NCT04359108</nct_id>
  </id_info>
  <brief_title>Environmental Localization Mapping and Guidance for Visual Prosthesis Users</brief_title>
  <acronym>SLAM</acronym>
  <official_title>Environmental Localization Mapping and Guidance for Visual Prosthesis Users</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>Johns Hopkins University</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
    <collaborator>
      <agency>Carnegie Mellon University</agency>
      <agency_class>Other</agency_class>
    </collaborator>
    <collaborator>
      <agency>National Eye Institute (NEI)</agency>
      <agency_class>NIH</agency_class>
    </collaborator>
  </sponsors>
  <source>Johns Hopkins University</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>Yes</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      This study is driven by the hypothesis that navigation for users of retinal prosthetics can
      be greatly improved by incorporating Spatial Localization and Mapping (SLAM) and object
      recognition technology conveying environmental information via a retinal prosthesis and
      auditory feedback. The investigators will study how effectively the SLAM technology enables
      the visual prosthesis system to construct a map of the user's environment and locate the user
      within that map. The technology will be tested both with normally sighted individuals donning
      a virtual reality headset and with retinal prosthesis users (Argus II).
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      About 1.3 million Americans aged 40 and older are legally blind, a majority because of
      diseases with onset later in life, such as glaucoma and age-related macular degeneration.
      Second Sight Medical Products (SSMP) has developed the world's first FDA approved retinal
      implant, Argus II, intended to restore some functional vision for people suffering from
      retinitis pigmentosa (RP). In this era of smart devices, generic navigation technology, such
      as GPS mapping apps for smartphones, can provide directions to help guide a blind user from
      point A to point B. However, these navigational aids do little to enable blind users to form
      an egocentric understanding of the surroundings, are not suited to navigation indoors, and do
      nothing to assist in avoiding obstacles to mobility. The Argus II, on the other hand,
      provides blind users with a limited visual representation of their surroundings that improves
      users' ability to orient themselves and traverse obstacles, yet lacks features for high-level
      navigation and semantic interpretation of the surroundings. The proposed study aims to
      address these limitations of the Argus II through a synergy of state-of-the-art simultaneous
      localization and mapping (SLAM) and object recognition technologies.

      This study is driven by the hypothesis that navigation for users of retinal prosthetics can
      be greatly improved by incorporating SLAM and object recognition technology conveying
      environmental information via a retinal prosthesis and auditory feedback. SLAM enables the
      visual prosthesis system to construct a map of the user's environment and locate the user
      within that map. The system then provides object location and navigational cues via
      appropriate sensory modalities enabling the user to mentally form an egocentric map of the
      environment. Investigators will develop and test a visual prosthesis system which 1)
      constructs a map of unfamiliar environments and localizes the user using SLAM technology 2)
      automatically identifies navigationally-relevant objects and landmarks using object
      recognition and 3) provides sensory feedback for navigation, obstacle avoidance, and
      object/landmark identification.
    </textblock>
  </detailed_description>
  <overall_status>Not yet recruiting</overall_status>
  <start_date type="Anticipated">December 1, 2020</start_date>
  <completion_date type="Anticipated">September 30, 2023</completion_date>
  <primary_completion_date type="Anticipated">September 30, 2023</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>N/A</allocation>
    <intervention_model>Single Group Assignment</intervention_model>
    <primary_purpose>Basic Science</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Accuracy as assessed as ratio of target identification success to total trials</measure>
    <time_frame>Up to 5 minutes</time_frame>
    <description>The participant will be asked to identify intended targets in a closed environment, as well as to navigate to intended targets. We will measure accuracy as the total number of successes divided by the total number of trials.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Trial Time as assessed by mean time duration to identify target</measure>
    <time_frame>Up to 5 minutes</time_frame>
    <description>This will be assessed by the mean duration of time to identify intended target (in seconds). For successful trials, the shorter the amount of time to conduct a task, the better the performance on said task.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Success in psychophysical judgments</measure>
    <time_frame>Trial Duration: estimated at up to one minute.</time_frame>
    <description>This will be assessed by the metric error in distance judgment, that is, the correctness of identification of judgments of target features. Measurement in meters.</description>
  </primary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Anticipated">35</enrollment>
  <condition>Retinitis Pigmentosa</condition>
  <condition>Visual Impairment</condition>
  <condition>Visual Prosthesis</condition>
  <arm_group>
    <arm_group_label>Navigation system for users of a visual prosthesis</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>This intervention will assess the feasibility of using a navigation system to aid blind users of a visual prosthesis with navigation tasks, by using the navigation system to provide navigational cues through multiple sensory modalities including vision and audition. The navigation system will be designed and developed as part of the proposed research and will interface with the Argus II retinal prosthesis system, which is an FDA approved visual prosthesis. Existing blind users of the Argus II device will be recruited for this study, and the navigation system will interface with these subjects' existing Argus II systems. Sighted subjects will also be recruited for this study, in which case the navigation system will interface with a head-mounted display (such as the Oculus Rift) worn by the sighted subjects that simulates the visual sensory information experienced by blind users of the Argus II retinal implant.</description>
  </arm_group>
  <intervention>
    <intervention_type>Device</intervention_type>
    <intervention_name>Navigation System for Users of a Visual Prosthesis</intervention_name>
    <description>We use common psychophysical judgments such as the following: discriminating between two alternatives by saying which is present in the field of view, touching a tablet computer to indicate the apparent location of a target in the frontal plane, and looking for targets by rotating the head and pointing when one is found. We will compare user performance using the Basic system with user performance using the Augmented and Augmented + Modal systems where contextual information associated with the task is conveyed to users via enhanced visual, auditory, and haptic modalities.</description>
    <arm_group_label>Navigation system for users of a visual prosthesis</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Criteria for inclusion of normally sighted individuals:

          -  Subject speaks English;

          -  Subjects must be between 20-55 years of age;

          -  Subject has the cognitive and communication ability to participate in the study (i.e.,
             follow spoken directions, perform tests, and give feedback);

          -  Subject is willing to conduct psychophysics testing up to 4-6 hours per day of testing
             on 3-5 consecutive days;

          -  Subject has visual acuity of 20/40 or better (corrected);

          -  Subject is capable of understanding participant information materials and giving
             written informed consent.

          -  Subject is able to walk unassisted

        Criteria for inclusion of Argus II users:

        The inclusion criteria for the study are the following:

          -  Subject is between 25-70 years of age;

          -  Subject has been implanted with the Argus II system;

          -  Subject's eye has healed from surgery and the surgeon has cleared the subject for
             programming;

          -  Subject has the cognitive and communication ability to participate in the study (i.e.,
             follow spoken directions, perform tests, and give feedback);

          -  Subject is willing to conduct psychophysics testing up to 4-6 hours per day of testing
             on 3-5 consecutive days;

          -  Subject is capable of understanding patient information materials and giving written
             informed consent;

          -  Subject is able to walk unassisted.

        Exclusion criteria for all subjects is the following:

          -  Subject is unwilling or unable to travel to testing facility for at least 3 days of
             testing within a one-week timeframe;

          -  Subject does not speak English;

          -  Subject has language or hearing impairment.

        The aim for the normally sighted group is to avoid any visual acuity issues that could
        impact the participant's performance in the study. Therefore, for the normally sighted
        group the maximum age is 55 in order to avoid common conditions that cause impaired vision
        or degraded visual acuity beyond that age. For the Argus II group, the minimum FDA-approved
        age for use of the Argus II device is 25 and we limit the maximum age to 70 in order to
        reduce mobility-related risks of injury for study participants, such as the risk of fall
        among the very elderly.
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>20 Years</minimum_age>
    <maximum_age>70 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Seth Billings, Ph.D.</last_name>
    <role>Principal Investigator</role>
    <affiliation>Johns Hopkins University</affiliation>
  </overall_official>
  <overall_contact>
    <last_name>Seth Billings, Ph.D.</last_name>
    <phone>4437787462</phone>
    <email>seth.billings@jhuapl.edu</email>
  </overall_contact>
  <overall_contact_backup>
    <last_name>Francesco Tenore, Ph.D.</last_name>
    <phone>4437789774</phone>
    <email>francesco.tenore@jhuapl.edu</email>
  </overall_contact_backup>
  <location>
    <facility>
      <name>Johns Hopkins Medicine - Wilmer Eye Institute</name>
      <address>
        <city>Baltimore</city>
        <state>Maryland</state>
        <zip>21205</zip>
        <country>United States</country>
      </address>
    </facility>
    <contact>
      <last_name>Gislin Dagnelie, PhD</last_name>
      <phone>410-614-4822</phone>
      <email>gislin@lions.med.jhu.edu</email>
    </contact>
    <investigator>
      <last_name>Gislin Dagnelie, PhD</last_name>
      <role>Principal Investigator</role>
    </investigator>
  </location>
  <location>
    <facility>
      <name>Johns Hopkins Applied Physics Laboratory</name>
      <address>
        <city>Laurel</city>
        <state>Maryland</state>
        <zip>20723</zip>
        <country>United States</country>
      </address>
    </facility>
    <contact>
      <last_name>Seth Billings, Ph.D.</last_name>
      <phone>443-778-7462</phone>
      <email>seth.billings@jhuapl.edu</email>
    </contact>
    <investigator>
      <last_name>Seth Billings, PhD</last_name>
      <role>Principal Investigator</role>
    </investigator>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <verification_date>July 2020</verification_date>
  <study_first_submitted>April 21, 2020</study_first_submitted>
  <study_first_submitted_qc>April 21, 2020</study_first_submitted_qc>
  <study_first_posted type="Actual">April 24, 2020</study_first_posted>
  <last_update_submitted>July 13, 2020</last_update_submitted>
  <last_update_submitted_qc>July 13, 2020</last_update_submitted_qc>
  <last_update_posted type="Actual">July 14, 2020</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <keyword>Retinal Prosthesis</keyword>
  <keyword>Argus II</keyword>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Vision Disorders</mesh_term>
    <mesh_term>Vision, Low</mesh_term>
    <mesh_term>Retinitis</mesh_term>
    <mesh_term>Retinitis Pigmentosa</mesh_term>
  </condition_browse>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
    <ipd_description>Results from this study will be disseminated through conference presentations and peer-reviewed publications. However, IPD will not be shared outside the study team.</ipd_description>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

