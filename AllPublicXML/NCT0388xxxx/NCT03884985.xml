<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on July 28, 2020</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03884985</url>
  </required_header>
  <id_info>
    <org_study_id>RSRB00069578</org_study_id>
    <secondary_id>R01EY029788-01</secondary_id>
    <nct_id>NCT03884985</nct_id>
  </id_info>
  <brief_title>Eye Movements, Visual Perception and Attention</brief_title>
  <official_title>Eye Movements, Visual Perception and Attention</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>University of Rochester</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
    <collaborator>
      <agency>National Eye Institute (NEI)</agency>
      <agency_class>NIH</agency_class>
    </collaborator>
  </sponsors>
  <source>University of Rochester</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      During visual fixation, small eye movements of which we are usually not aware, prevent the
      maintenance of a steady direction of gaze. These eye movements are finely controlled and
      shift retinal projection of objects within the fovea, the region of the retina where visual
      acuity is highest. This program of research examines the link between these eye movements and
      attention, and tests the hypothesis that attention, similarly to eye movements, can be
      controlled at the foveal level. Psychophysical experiments with human subjects, using
      state-of-the-art techniques, high resolution eyetracking and retinal stabilization are
      conducted to address these questions. Gaze-contingent calibration procedures are employed to
      achieve high accuracy in gaze localization. A custom developed gaze-contingent display is
      used to shift in real-time visual stimuli on the monitor to compensate for the observer eye
      movements during fixation periods and to maintain stimuli at a desired location on the
      retina. Experiments involve visual discrimination/detection tasks with stimuli presented at
      selected eccentricities within the fovea. Participants' performance and reaction times are
      examined under different conditions, in which various types of attention are manipulated. In
      addition to advancing our basic understanding of visual perception, this research leads to a
      better understanding of attentional control at the foveal scale and of the contribution of
      microscopic eye movements to the acquisition and processing of visual details.
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      The goals of this study are to the following:

        1. Examine the resolution and time-course of attention within the foveola. Attentional
           control has been traditionally studied outside the foveola but the PI's recent work
           suggests that attentional shifts also play a critical role in the normal examination of
           fine spatial details. Building on our previous results, we will investigate the extent
           by which both voluntary and involuntary attention can be controlled at this scale.
           Specifically, we will (a) measure the resolution of attention, i.e., the minimum
           distance between two locations within the foveola that can elicit selective voluntary
           attentional shifts. We will (b) examine whether enhancements in fine spatial vision at
           selected foveal locations, such as those we have previously shown for voluntary
           attention, also occur with involuntary attention. Finally we will study (c) the
           time-course of attentional enhancements and inhibition of return at this scale.
           Moreover, to study how peripheral and foveal attention differ, we will compare the
           extent of exogenous attentional effects and their time-course within and outside the
           foveola.

        2. Map visual acuity and crowding across the foveola. Our research has shown that vision is
           not uniform across the foveola: discrimination of fine spatial patterns is already
           suboptimal just a few arcmins away from the center of gaze. This phenomenon could be
           caused by a decline in visual acuity outside the preferred retinal locus and/or the
           consequences of crowding, the negative influence resulting from objects adjacent to the
           target. Because of the difficulty in precisely controlling retinal stimulation at this
           scale, it is unclear whether crowding occurs in the foveola, and whether its influence
           changes with foveal eccentricity. We will measure both visual acuity (a), and crowding
           (b), and will assess their relative contribution over a range of foveal eccentricities,
           both nasally and temporally. In addition to examine visual acuity across subjects, we
           will also examine how it changes at the individual level.

        3. Link attention, fine spatial vision and oculomotor control. Microsaccades normally shift
           the retinal projection of the fixated object across the foveola. At a larger scale,
           visual resolution, attention, and eye movements are tightly coupled. But little is known
           on whether and how this interplay unfolds within the foveola. Here we will investigate
           how attention and vision interact with microsaccades preparation and execution. We will
           examine (a) whether microsaccades preparation yields attentional benefits at specific
           foveal locations; (b) the precision of microsaccades; (c) their impact in attenuating
           negative effects of reduced acuity and foveal crowding, and; (d) their impact on
           performance in natural high acuity tasks.

      To address these goals psychophysics experimental paradigms and high-precision eyetracking
      will be used.
    </textblock>
  </detailed_description>
  <overall_status>Recruiting</overall_status>
  <start_date type="Actual">January 1, 2015</start_date>
  <completion_date type="Anticipated">February 1, 2023</completion_date>
  <primary_completion_date type="Anticipated">February 1, 2023</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>N/A</allocation>
    <intervention_model>Single Group Assignment</intervention_model>
    <primary_purpose>Basic Science</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Average Performance in Visual tasks</measure>
    <time_frame>Day 0</time_frame>
    <description>Proportion correct responses in visual tasks</description>
  </primary_outcome>
  <secondary_outcome>
    <measure>Microsaccades rate</measure>
    <time_frame>Day 0</time_frame>
    <description>Average number of microsaccades per second</description>
  </secondary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Anticipated">50</enrollment>
  <condition>Vision</condition>
  <arm_group>
    <arm_group_label>Normal Vision</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>This study examines high-acuity vision, oculomotor behavior recorded using high-resolution eyetracking. Healthy participants are asked to perform different types of visual tasks, ranging from letter identification to judging facial expressions while their eye movements will be recorded with high-precision together with their behavioral performance in the task.</description>
  </arm_group>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Visual stimulation</intervention_name>
    <description>In the experiments, participants will sit in front of a computer monitor located a less than a meter of distance and will analyze the content of images extracted from collections of natural and computer-generated scenes. Subjects will be asked to report verbally or by pressing keys on a keyboard on image characteristics such as the locations of the objects present in the scenes, their number and/or their identities. Some experiments will involve a search paradigm in which subjects will have to report on the location and/or fine characteristics of a target element among a field of distracting similar elements, and/or visual discrimination tasks. The duration of the interval of time in which the image is maintained on the screen may be varied between few tens of milliseconds to several seconds. In a set of experiments, the eye movements performed by the subjects during the execution of the visual tasks will be recorded as explained below.</description>
    <arm_group_label>Normal Vision</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:

          -  Subjects will be eligible for the study if they:

               -  Are at least 18 years old

               -  Speak English

               -  Have read, understood, and signed the informed consent form Have normal visual
                  acuity (20/20 or better) without correction (i.e. without glasses or contact
                  lenses) and no known visual deficits. A standard visual acuity screening will be
                  performed by means of a Snellen chart (the standard eye chart) at the beginning
                  and the end of the experiments.

        Exclusion Criteria:

          -  Subjects will be excluded if they:

               -  Are under 18 years old

               -  Cannot understand the experimental procedures Have reported vision loss,
                  including the need for correction (i.e. glasses or contact lenses), or fail the
                  visual acuity screening performed during the experiments. We expect a very minor
                  portion of subjects to be excluded as a result of this test, as the good vision
                  requirement will be clearly stated in our recruitment materials. There will be no
                  data collection for subjects who will not pass the acuity test.
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>18 Years</minimum_age>
    <maximum_age>N/A</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Martina Poletti, Ph.D.</last_name>
    <role>Principal Investigator</role>
    <affiliation>University of Rochester</affiliation>
  </overall_official>
  <overall_contact>
    <last_name>Martina Poletti, Ph.D.</last_name>
    <phone>6175953785</phone>
    <email>martina.poletti@gmail.com</email>
  </overall_contact>
  <location>
    <facility>
      <name>University of Rochester</name>
      <address>
        <city>Rochester</city>
        <state>New York</state>
        <zip>14642</zip>
        <country>United States</country>
      </address>
    </facility>
    <status>Recruiting</status>
    <contact>
      <last_name>Martina Poletti, Ph.D.</last_name>
      <phone>617-595-3785</phone>
      <email>martina.poletti@gmail.com</email>
    </contact>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <verification_date>March 2020</verification_date>
  <study_first_submitted>March 20, 2019</study_first_submitted>
  <study_first_submitted_qc>March 20, 2019</study_first_submitted_qc>
  <study_first_posted type="Actual">March 21, 2019</study_first_posted>
  <last_update_submitted>March 11, 2020</last_update_submitted>
  <last_update_submitted_qc>March 11, 2020</last_update_submitted_qc>
  <last_update_posted type="Actual">March 16, 2020</last_update_posted>
  <responsible_party>
    <responsible_party_type>Principal Investigator</responsible_party_type>
    <investigator_affiliation>University of Rochester</investigator_affiliation>
    <investigator_full_name>Martina Poletti</investigator_full_name>
    <investigator_title>Assistant Professor</investigator_title>
  </responsible_party>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

