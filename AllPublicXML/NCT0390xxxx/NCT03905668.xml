<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on July 28, 2020</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03905668</url>
  </required_header>
  <id_info>
    <org_study_id>IRB201900354 -N</org_study_id>
    <secondary_id>1R21EB027344-01</secondary_id>
    <secondary_id>1750192</secondary_id>
    <secondary_id>OCR20330</secondary_id>
    <nct_id>NCT03905668</nct_id>
  </id_info>
  <brief_title>Intelligent ICU of the Future</brief_title>
  <official_title>Title:Intelligent ICU of the Future Subtitle 1: Autonomous Pain Recognition in Non-Verbal and Critically Ill Patients Subtitle 2: Fundamental Intelligent Building Blocks of the Intensive Care Unit (ICU) of the Future</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>University of Florida</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
    <collaborator>
      <agency>National Institute for Biomedical Imaging and Bioengineering (NIBIB)</agency>
      <agency_class>NIH</agency_class>
    </collaborator>
    <collaborator>
      <agency>U.S. National Science Foundation</agency>
      <agency_class>U.S. Fed</agency_class>
    </collaborator>
  </sponsors>
  <source>University of Florida</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      The objective of this project is to create deep learning and machine learning models capable
      of recognizing patient visual cues, including facial expressions such as pain and functional
      activity. Many important details related to the visual assessment of patients, such as facial
      expressions like pain, head and extremity movements, posture, and mobility are captured
      sporadically by overburdened nurses or are not captured at all. Consequently, these important
      visual cues, although associated with critical indices, such as physical functioning, pain,
      and impending clinical deterioration, often cannot be incorporated into clinical status. The
      study team will develop a sensing system to recognize facial and body movements as patient
      visual cues. As part of a secondary evaluation method the study team will assess the models
      ability to detect delirium.
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Pain is a critical national health problem with nearly 50% of critical care patients
      experience significant pain in the Intensive Care Unit (ICU). The under-assessment of pain
      response is one of the primary barriers to the adequate treatment of pain in critically ill
      patients, associated with many negative outcomes such as chronic pain after discharge,
      prolonged mechanical ventilation, longer ICU stay, and increased mortality risk. Nonetheless,
      many ICU patients are unable to self-report pain intensity due to clinical conditions,
      ventilation devices, and altered consciousness. Currently, behavioral pain scales are used to
      assess pain in nonverbal patients. Unfortunately, these scales require repetitive manual
      administration by overburdened nurses. Moreover, prior work suggests that nurses caring for
      quasi-sedated patients in critical care settings have considerable variability in pain
      intensity ratings. Furthermore, manual pain assessment tools lack the capability to monitor
      pain continuously and autonomously. Together, these challenges point to a critical need for
      developing objective and autonomous pain recognition systems.

      Delirium is another common complication of hospitalization that poses significant health
      problems in hospitalized patients. It is most prevalent in surgical ICU patients with
      diagnosis rates up to 80%. It is characterized by changes in cognition, activity level,
      consciousness, and alertness. Delirium typically leads to changes in activity level and
      alertness that pose additional health risks including risk of fall, inadequate mobilization,
      disturbed sleep, inadequate pain control, and negative emotions. All of these effects are
      difficult to monitor in real-time and further contribute to worsening of patient's cognitive
      abilities, inhibit recovery, and slow down the rehabilitation process. Though about a third
      of delirium cases can benefit from intervention, detecting and predicting delirium is still
      very limited in practice. Current Delirium assessments need to be performed by trained
      healthcare staff, are time consuming, and resource intensive. Due to the resources necessary
      to complete the assessment, delirium is often assessed twice per day, despite the transient
      nature of the disease state which can come and go undetected between the assessments. Jointly
      these obstacles demonstrate a dire need for real-time autonomous delirium detection.

      The investigators hypothesize that the proposed model would be able to leverage
      accelerometer, electromyographic, and video data for the purpose of autonomously quantifying
      patient facial expressions such as pain, characterizing functional activities, and delirium
      status. Rationalizing that autonomous visual cue quantification and delirium detection can
      reduce nurse workload and can enable real-time pain and delirium monitoring. Early detection
      of delirium offers patients the best chance for good delirium treatment outcomes.
    </textblock>
  </detailed_description>
  <overall_status>Recruiting</overall_status>
  <start_date type="Actual">November 25, 2019</start_date>
  <completion_date type="Anticipated">March 2022</completion_date>
  <primary_completion_date type="Anticipated">March 2022</primary_completion_date>
  <study_type>Observational</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <observational_model>Case-Only</observational_model>
    <time_perspective>Prospective</time_perspective>
  </study_design_info>
  <primary_outcome>
    <measure>Defense Veterans Pain Reporting Scale (DVPRS)</measure>
    <time_frame>Before hospital discharge, up to Day 8</time_frame>
    <description>Before discharge, patients will be shown three short video clips from their ICU admission and asked to rate their pain levels using the Defense Veterans Pain Reporting Scale. DVPRS is a 10 point visual scale used to self report pain (0-4 being mild pain; 5-7 being moderate pain; 8-10 being severe pain).</description>
  </primary_outcome>
  <number_of_groups>2</number_of_groups>
  <enrollment type="Anticipated">1000</enrollment>
  <condition>Pain</condition>
  <condition>Delirium</condition>
  <arm_group>
    <arm_group_label>ICU Patients</arm_group_label>
    <description>Adults in admitted to an ICU at University of Florida Health Gainesville with an expected length of stay greater than 24 hours which are not on any form of contact precaution or isolation. Patients will have continuous video, accelerometer, and electromyographic monitoring for up to seven days while in the ICU.</description>
  </arm_group>
  <arm_group>
    <arm_group_label>ICU Patient Friends/Family Members</arm_group_label>
    <description>Adult visitors of participating ICU patients that are willing to provide feedback to the learning algorithms.</description>
  </arm_group>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Video Monitoring</intervention_name>
    <description>Patients may have video monitoring for up to seven days while in the ICU. The video system will be placed in an unobtrusive area in the patient's ICU room.</description>
    <arm_group_label>ICU Patients</arm_group_label>
  </intervention>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Accelerometer Monitoring</intervention_name>
    <description>Patients may have accelerometer monitoring for up to seven days while in the ICU. Commercially available accelerometer units, which have been validated in previous clinical studies, will be used.</description>
    <arm_group_label>ICU Patients</arm_group_label>
  </intervention>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Electromyographic Monitoring</intervention_name>
    <description>Patients may have electromyographic monitoring for up to seven days while in the ICU.</description>
    <arm_group_label>ICU Patients</arm_group_label>
    <other_name>EMG monitoring</other_name>
  </intervention>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Noise Level Monitoring</intervention_name>
    <description>Patients may have noise level monitoring (in decibels) for up to seven days while in the ICU.</description>
    <arm_group_label>ICU Patients</arm_group_label>
  </intervention>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Light Level Monitoring</intervention_name>
    <description>Patients may have light level monitoring for up to seven days while in the ICU.</description>
    <arm_group_label>ICU Patients</arm_group_label>
  </intervention>
  <eligibility>
    <study_pop>
      <textblock>
        Adults in the ICU or Adults visiting recruited patients in the ICU
      </textblock>
    </study_pop>
    <sampling_method>Non-Probability Sample</sampling_method>
    <criteria>
      <textblock>
        ICU Patients:

        Inclusion Criteria:

          -  patient admitted to University of Florida (UF) Health Gainesville ICU

        Exclusion Criteria:

          -  Anticipated ICU stay is less than one day

          -  Patient is on any form of contact precaution or isolation

          -  Patient is unable to wear a Shimmer3 unit

        ICU Patient Friends/Family:

        Inclusion Criteria:

          -  Individual has their name designated on a patient's informed consent form giving them
             permission to view and modify facial and activity data collected about that patient

        Exclusion Criteria:

          -  Age &lt; 18

          -  They are unable to answer short questions on a touch screen display

          -  They are unable to wear a proximity sensor

          -  They were not on the listed of designated individuals specified in their friend/family
             members informed consent form
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>18 Years</minimum_age>
    <maximum_age>100 Years</maximum_age>
    <healthy_volunteers>No</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Azra Bihorac, MD</last_name>
    <role>Principal Investigator</role>
    <affiliation>University of Florida</affiliation>
  </overall_official>
  <overall_contact>
    <last_name>Matthew Ruppert, BS</last_name>
    <phone>352-294-8723</phone>
    <email>Ruppert20@ufl.edu</email>
  </overall_contact>
  <location>
    <facility>
      <name>UF Health Shands Hospital</name>
      <address>
        <city>Gainesville</city>
        <state>Florida</state>
        <zip>32608</zip>
        <country>United States</country>
      </address>
    </facility>
    <status>Recruiting</status>
    <contact>
      <last_name>Matthew Ruppert, BS</last_name>
      <phone>352-294-8723</phone>
      <email>Matthew.Ruppert@Medicine.ufl.edu</email>
    </contact>
    <contact_backup>
      <last_name>Haleh Hashemighouchani, MD</last_name>
      <phone>352-294-8776</phone>
      <email>Haleh.Hashemighouchani@medicine.ufl.edu</email>
    </contact_backup>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <verification_date>December 2019</verification_date>
  <study_first_submitted>April 3, 2019</study_first_submitted>
  <study_first_submitted_qc>April 4, 2019</study_first_submitted_qc>
  <study_first_posted type="Actual">April 5, 2019</study_first_posted>
  <last_update_submitted>December 3, 2019</last_update_submitted>
  <last_update_submitted_qc>December 3, 2019</last_update_submitted_qc>
  <last_update_posted type="Actual">December 5, 2019</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Delirium</mesh_term>
  </condition_browse>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

