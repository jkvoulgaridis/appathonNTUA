<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on July 28, 2020</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03867032</url>
  </required_header>
  <id_info>
    <org_study_id>Zhou_R01_study5</org_study_id>
    <nct_id>NCT03867032</nct_id>
  </id_info>
  <brief_title>Auditory Training With Speech Related Acoustic Cues Using Psychophysical Testing</brief_title>
  <official_title>Auditory Training With Speech Related Acoustic Cues Using Psychophysical Testing</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>East Carolina University</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>East Carolina University</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      In this study, the investigators will evaluate whether auditory training with speech-related
      acoustic features in psychophysical testing will help CI subjects improve speech recognition.
      The primary endpoint is the speech recognition measures.
    </textblock>
  </brief_summary>
  <overall_status>Not yet recruiting</overall_status>
  <start_date type="Anticipated">August 2021</start_date>
  <completion_date type="Anticipated">December 2025</completion_date>
  <primary_completion_date type="Anticipated">December 2025</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>N/A</allocation>
    <intervention_model>Single Group Assignment</intervention_model>
    <primary_purpose>Basic Science</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>speech recognition after training</measure>
    <time_frame>starting 12 months after the award and will take up to 3.5 years to complete</time_frame>
    <description>Subjects will be measured for their baseline speech recognition performance (A) and then measured again for speech recognition after receiving auditory training using the psychophysical methods (B). Finally, the subjects will be measured for speech recognition the third time after the training is withdrawn following a ABA longitudinal design.</description>
  </primary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Anticipated">20</enrollment>
  <condition>Deafness</condition>
  <arm_group>
    <arm_group_label>Cochlear implant users</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>The group will receive auditory training (psychophysical), and will be evaluated for speech recognition to determine the effect of training.</description>
  </arm_group>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Auditory training</intervention_name>
    <description>Training with psychophysical tests (amplitude modulation detection on single electrodes) for improving speech recognition</description>
    <arm_group_label>Cochlear implant users</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:

          -  Native speakers of English

          -  Cochlear Nucleus cochlear implant users or Advanced Bionics users

          -  Postlingually deafened

          -  Has had device experience for at least one year

          -  Can be child or adult at the time of enrollment

        Exclusion Criteria:

          -  None
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>10 Years</minimum_age>
    <maximum_age>N/A</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_contact>
    <last_name>Ning Zhou, PhD</last_name>
    <phone>252-744-6147</phone>
    <email>zhoun@ecu.edu</email>
  </overall_contact>
  <reference>
    <citation>Banai K, Hornickel J, Skoe E, Nicol T, Zecker S, Kraus N. Reading and subcortical auditory function. Cereb Cortex. 2009 Nov;19(11):2699-707. doi: 10.1093/cercor/bhp024. Epub 2009 Mar 17.</citation>
    <PMID>19293398</PMID>
  </reference>
  <reference>
    <citation>Baumann S, Joly O, Rees A, Petkov CI, Sun L, Thiele A, Griffiths TD. The topography of frequency and time representation in primate auditory cortices. Elife. 2015 Jan 15;4. doi: 10.7554/eLife.03256.</citation>
    <PMID>25590651</PMID>
  </reference>
  <reference>
    <citation>Boebinger D, Evans S, Rosen S, Lima CF, Manly T, Scott SK. Musicians and non-musicians are equally adept at perceiving masked speech. J Acoust Soc Am. 2015 Jan;137(1):378-87. doi: 10.1121/1.4904537.</citation>
    <PMID>25618067</PMID>
  </reference>
  <reference>
    <citation>Chen JK, Chuang AY, McMahon C, Hsieh JC, Tung TH, Li LP. Music training improves pitch perception in prelingually deafened children with cochlear implants. Pediatrics. 2010 Apr;125(4):e793-800. doi: 10.1542/peds.2008-3620. Epub 2010 Mar 8.</citation>
    <PMID>20211951</PMID>
  </reference>
  <reference>
    <citation>Coffey EBJ, Mogilever NB, Zatorre RJ. Speech-in-noise perception in musicians: A review. Hear Res. 2017 Sep;352:49-69. doi: 10.1016/j.heares.2017.02.006. Epub 2017 Feb 14. Review.</citation>
    <PMID>28213134</PMID>
  </reference>
  <reference>
    <citation>Fritz J, Elhilali M, Shamma S. Active listening: task-dependent plasticity of spectrotemporal receptive fields in primary auditory cortex. Hear Res. 2005 Aug;206(1-2):159-76. Review.</citation>
    <PMID>16081006</PMID>
  </reference>
  <reference>
    <citation>Fitzgerald MB, Wright BA. Perceptual learning and generalization resulting from training on an auditory amplitude-modulation detection task. J Acoust Soc Am. 2011 Feb;129(2):898-906. doi: 10.1121/1.3531841.</citation>
    <PMID>21361447</PMID>
  </reference>
  <reference>
    <citation>Fu QJ, Galvin JJ 3rd, Wang X, Wu JL. Benefits of music training in mandarin-speaking pediatric cochlear implant users. J Speech Lang Hear Res. 2015 Feb;58(1):163-9. doi: 10.1044/2014_JSLHR-H-14-0127.</citation>
    <PMID>25321148</PMID>
  </reference>
  <reference>
    <citation>Huyck JJ, Wright BA. Learning, worsening, and generalization in response to auditory perceptual training during adolescence. J Acoust Soc Am. 2013 Aug;134(2):1172-82. doi: 10.1121/1.4812258.</citation>
    <PMID>23927116</PMID>
  </reference>
  <reference>
    <citation>Looi V, Gfeller K, Driscoll V. MUSIC APPRECIATION AND TRAINING FOR COCHLEAR IMPLANT RECIPIENTS: A REVIEW. Semin Hear. 2012 Nov 1;33(4):307-334. Epub 2012 Nov 19.</citation>
    <PMID>23459244</PMID>
  </reference>
  <reference>
    <citation>Parbery-Clark A, Skoe E, Kraus N. Musical experience limits the degradative effects of background noise on the neural processing of sound. J Neurosci. 2009 Nov 11;29(45):14100-7. doi: 10.1523/JNEUROSCI.3256-09.2009.</citation>
    <PMID>19906958</PMID>
  </reference>
  <reference>
    <citation>Patel AD. Why would Musical Training Benefit the Neural Encoding of Speech? The OPERA Hypothesis. Front Psychol. 2011 Jun 29;2:142. doi: 10.3389/fpsyg.2011.00142. eCollection 2011.</citation>
    <PMID>21747773</PMID>
  </reference>
  <reference>
    <citation>Polley DB, Steinberg EE, Merzenich MM. Perceptual learning directs auditory cortical map reorganization through top-down influences. J Neurosci. 2006 May 3;26(18):4970-82.</citation>
    <PMID>16672673</PMID>
  </reference>
  <reference>
    <citation>Ruggles DR, Freyman RL, Oxenham AJ. Influence of musical training on understanding voiced and whispered speech in noise. PLoS One. 2014 Jan 28;9(1):e86980. doi: 10.1371/journal.pone.0086980. eCollection 2014.</citation>
    <PMID>24489819</PMID>
  </reference>
  <reference>
    <citation>Sabin AT, Eddins DA, Wright BA. Perceptual learning evidence for tuning to spectrotemporal modulation in the human auditory system. J Neurosci. 2012 May 9;32(19):6542-9. doi: 10.1523/JNEUROSCI.5732-11.2012.</citation>
    <PMID>22573676</PMID>
  </reference>
  <reference>
    <citation>Szpiro SF, Wright BA, Carrasco M. Learning one task by interleaving practice with another task. Vision Res. 2014 Aug;101:118-24. doi: 10.1016/j.visres.2014.06.004. Epub 2014 Jun 21.</citation>
    <PMID>24959653</PMID>
  </reference>
  <reference>
    <citation>Wright BA, Sabin AT, Zhang Y, Marrone N, Fitzgerald MB. Enhancing perceptual learning by combining practice with periods of additional sensory stimulation. J Neurosci. 2010 Sep 22;30(38):12868-77. doi: 10.1523/JNEUROSCI.0487-10.2010.</citation>
    <PMID>20861390</PMID>
  </reference>
  <reference>
    <citation>Yucel E, Sennaroglu G, Belgin E. The family oriented musical training for children with cochlear implants: speech and musical perception results of two year follow-up. Int J Pediatr Otorhinolaryngol. 2009 Jul;73(7):1043-52. doi: 10.1016/j.ijporl.2009.04.009. Epub 2009 May 2.</citation>
    <PMID>19411117</PMID>
  </reference>
  <verification_date>July 2020</verification_date>
  <study_first_submitted>March 5, 2019</study_first_submitted>
  <study_first_submitted_qc>March 6, 2019</study_first_submitted_qc>
  <study_first_posted type="Actual">March 7, 2019</study_first_posted>
  <last_update_submitted>July 13, 2020</last_update_submitted>
  <last_update_submitted_qc>July 13, 2020</last_update_submitted_qc>
  <last_update_posted type="Actual">July 14, 2020</last_update_posted>
  <responsible_party>
    <responsible_party_type>Principal Investigator</responsible_party_type>
    <investigator_affiliation>East Carolina University</investigator_affiliation>
    <investigator_full_name>Ning Zhou</investigator_full_name>
    <investigator_title>Associate Professor</investigator_title>
  </responsible_party>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Deafness</mesh_term>
  </condition_browse>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

