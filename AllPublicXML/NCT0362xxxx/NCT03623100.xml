<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on July 28, 2020</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03623100</url>
  </required_header>
  <id_info>
    <org_study_id>R15DC013359</org_study_id>
    <secondary_id>7R15DC013359</secondary_id>
    <nct_id>NCT03623100</nct_id>
  </id_info>
  <brief_title>Neural Indices of Intervention Outcomes in Children With Speech Sound Disorders</brief_title>
  <official_title>Identification of Electrophysiological Indices of Speech Sound Perception and Change in Children With Speech Sound Disorders</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>Idaho State University</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
    <collaborator>
      <agency>National Institute on Deafness and Other Communication Disorders (NIDCD)</agency>
      <agency_class>NIH</agency_class>
    </collaborator>
  </sponsors>
  <source>Idaho State University</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      Children with speech sound disorders (SSD) are thought to be unable to detect subtle
      differences between sounds, though there is little understanding of the underlying perceptual
      mechanisms implicated in SSD. The investigators suggest that children with SSD may have
      difficulty creating phonological representations due to inaccurate perception and
      representation of speech sounds, which then directly impacts speech production abilities.
      Children will be randomly assigned to one of two treatment conditions in the present study:
      1) Traditional speech treatment alone or 2) Traditional speech treatment in conjunction with
      speech perceptual training. By identifying an underlying mechanism of the disorder, the
      clinical approach to the treatment of SSD will be better informed and treatment approaches
      targeting all deficient areas can be utilized.
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Five to eight percent of all children in the United States have a speech sound disorder
      (SSD). Children with SSD have difficulty producing sounds of their target language system.
      Some of these children also have difficulty perceiving and categorizing speech sounds. It is
      presently unknown what underlying mechanisms might account for the communication problems
      children with SSD encounter. One possible explanation is that children with SSD cannot
      produce speech sounds correctly because they have poorly specified phonological
      representations, which are the result of inaccurate speech sound perception. Thus, speech
      sound production errors may stem from imprecise speech perception and its resulting sparse
      phonological representations.

      Most children with SSD make slow and steady gains in speech treatment. This is likely due to
      the fact that speech treatment typically targets just phonetics (i.e., speech production) and
      phonology (i.e., speech sound knowledge and use). However, it is possible that the underlying
      mechanisms of speech sound disorders are not specifically phonological in nature but may in
      fact be related to more general cognitive and/or linguistic impairments. Thus, children will
      be randomly assigned to one of two treatment conditions in the present study: 1) Traditional
      speech treatment alone or 2) Traditional speech treatment in conjunction with speech
      perceptual training.

      One goal of the research program is to identify what components of treatment induce the
      greatest amount of phonological change in children with SSD. By comparing the treatment
      components, the investigators will be able to identify what treatment activities induce the
      greatest phonological change in children. This information should aid in developing more
      efficient and effective treatment programs for SSD.

      A second goal of the research program to use electrophysiological measures
      (electroencephalogram, EEG; event-related potentials, ERP; frequency following responses,
      FFR) to examine how phonological representations and their associated auditory neural
      responses change in conjunction with the two traditional speech treatment approaches. A
      better understanding of phonological representations and the auditory sensory system in
      children with SSD will inform how speech evaluations and treatment are best conducted by
      speech-language pathologists.
    </textblock>
  </detailed_description>
  <overall_status>Recruiting</overall_status>
  <start_date type="Actual">August 1, 2014</start_date>
  <completion_date type="Anticipated">July 31, 2025</completion_date>
  <primary_completion_date type="Anticipated">July 31, 2022</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>Randomized</allocation>
    <intervention_model>Parallel Assignment</intervention_model>
    <intervention_model_description>A single-subject staggered multiple baseline design will be used in the speech treatment program. Following procedures for this design, the children with SSD will be randomly assigned to one of two treatment conditions. These groups will be evaluated independently and in combination. Every subject will be evaluated in a baseline period in which no treatment is provided. Every subject will first complete a full baseline assessment. Subsequent baselines will consist only of a shorter baseline probe that specifically targets the phonemes each child did not produce during the initial baseline session. Thus, the first subject in each condition will have 2 baselines and then begin treatment. Each subsequent subject within each condition will have 1 additional baseline before beginning treatment.</intervention_model_description>
    <primary_purpose>Treatment</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Change from baseline treated sound production accuracy at four months</measure>
    <time_frame>an average of 4 months</time_frame>
    <description>Each treated sound will be point-by-point identified as being correct or incorrect in relation to its target phoneme. From these values, generalization data from each child will be examined from both descriptive and quantitative perspectives. Generalization will be descriptively defined using the learning criterion level of 10% or greater accuracy change in treated phonemes (Gierut &amp; Morrisette, 2012a). For each child and each condition, generalization will be examined to see if the 10% criterion is met. Quantitatively, the amount of change from pre- to post-intervention in treated phoneme accuracy will be calculated separately for each child.</description>
  </primary_outcome>
  <secondary_outcome>
    <measure>Change from baseline Mismatch Negativity (MMN) mean amplitude at four months</measure>
    <time_frame>an average of 4 months</time_frame>
    <description>Given that the MMN is typically maximal over fronto-central midline electrode sites (e.g., Fz, FCz, and Cz) (Naatanen, Teder, Alho, &amp; Lavikainen, 1992), these three electrodes will be selected for the mean MMN amplitude analyses. Each maximal peak latency will be first measured in the grand averaged waveforms using the ERPLAB Toolbox (Luck &amp; Lopez-Calderon, 2012) across the 100-400 ms time window. Peak latencies elicited by the treated sound syllable and ba stimuli will be averaged across the three electrodes to determine the center latency of each peak. The center latency will be then used to align a 100 ms window (50 ms on either side) to measure the mean amplitudes for all electrodes and stimulus types. It is likely that the MMN mean amplitude window will be approximately 250-350 ms.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Change from baseline P1/P2 mean amplitude at four months</measure>
    <time_frame>an average of 4 months</time_frame>
    <description>As every participant might not demonstrate a clear and measurable MMN peak (Cummings, Madden, &amp; Hefta, 2017), mean amplitude measurements of the auditory P1/P2 ERP peak in the standard and deviant waveforms will also be taken as an additional measure of neural change occurring in conjunction with speech treatment. Three regions of interest (ROI) have been defined and electrodes for each ROI are defined as follows. Left hemisphere ROI channels are F5, FC5, and C5; midline ROI channels are Fz, FCz, and Cz; right hemisphere ROI channels are F6, FC6, and C6. The P1/P2 mean amplitude will be measured across a 100 ms window (100-200 ms post-syllable onset) for both the treated sound syllable and ba for all nine electrodes. The median P1/P2 amplitude for each subject and each ROI for both the pre-treatment and post-treatment assessments will then be calculated.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Event-related spectral perturbation (ERSP) channel analyses</measure>
    <time_frame>an average of 4 months</time_frame>
    <description>ERSP channel analyses will be completed to examine theta (3-6 Hz) and alpha (8-13 Hz) band activity changes occurring in conjunction with speech treatment for both the treated sound and ba syllables. Data from all children will be included in the channel analyses. A left hemisphere region of interest (ROI) and a right hemisphere ROI have been identified to include channels associated with right and left IFG. The left ROI includes the following channels: F5, FC5, C5, F3, FC3, C3; the right ROI includes: F6, FC6, C6, F4, FC4, C4.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Change from baseline frequency following responses (FFRs) at four months</measure>
    <time_frame>an average of 4 months</time_frame>
    <description>The timing, stability, and magnitude of FFRs elicited by consonants have been linked to children's phonological awareness and literacy skills (White-Schwoch et al., 2015). Thus, FFRs, as well as traditional auditory brainstem response (ABR) peaks, will be measured. For each FFR/ABR peak, grand average latency and amplitude measurements will be completed.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Event-related spectral perturbation (ERSP) independent component (IC) analyses</measure>
    <time_frame>an average of 4 months</time_frame>
    <description>ERSP IC analyses will be completed to examine theta (3-6 Hz) and alpha (8-13 Hz) band activity changes occurring in conjunction with speech treatment for both the treated sound and ba syllables. Completing the IC cluster analyses will involve multiple steps. First, the pre- and post-treatment data for the treated sound and ba syllables will be put into separate studies in EEGLAB to examine neural changes occurring in conjunction with speech treatment. EEG component clusters will be identified for each of studies; not every subject is predicted to contribute data to each cluster. To limit the number of analyses, only clusters that have dipoles associated with the right and left inferior frontal gyrus (IFG) will be included. Moreover, the IC cluster analyses will only include data from subjects who have identifiable clusters present in both pre- and post-treatment assessments.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Change from baseline Percent Consonants Correct (PCC) at four months</measure>
    <time_frame>an average of 4 months</time_frame>
    <description>All consonants will be point-by-point identified as being correct or incorrect in relation to its target phoneme. From these values, generalization data from each child will be examined from both descriptive and quantitative perspectives. Generalization will be descriptively defined using the learning criterion level of 10% or greater accuracy change in PCC scores (Gierut &amp; Morrisette, 2012a). For each child and each condition, generalization will be examined to see if the 10% criterion is met. Quantitatively, the amount of change from pre- to post-intervention in PCC accuracy will be calculated separately for each child.</description>
  </secondary_outcome>
  <number_of_arms>2</number_of_arms>
  <enrollment type="Anticipated">60</enrollment>
  <condition>Speech Sound Disorder</condition>
  <arm_group>
    <arm_group_label>Speech Treatment</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>Half of the children will be assigned to the traditional speech treatment program which will focus on how to produce sounds in academic vocabulary words.</description>
  </arm_group>
  <arm_group>
    <arm_group_label>Speech Treatment &amp; Perception</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>Half of the children will be assigned to the traditional speech treatment program and speech perception training program combination. This treatment program will teach children not only how to produce sounds in academic vocabulary words, but to also identify correctly and incorrectly produced sounds in words.</description>
  </arm_group>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Speech Production Treatment.</intervention_name>
    <description>Speech production treatment will be delivered in two phases: Imitation and Spontaneous Production. Treatment will be provided two times weekly in 1-hour sessions, for up to 19 sessions. Every child's intervention program will target a single phoneme that was excluded from his or her phonemic inventory. Each treatment phoneme will be targeted through the production of five words that will be initially introduced to the child using a storybook reading format. Imitation treatment will continue until a child maintains 75% accurate production of the treated phoneme over two consecutive sessions (i.e. performance-based criterion) or until seven consecutive sessions are completed (i.e. time-based criterion). Spontaneous Production will continue until the child maintains either a performance-based criterion of 90% accurate production of the treated phoneme over 3 consecutive sessions, or a time-based criterion of 12 consecutive sessions.</description>
    <arm_group_label>Speech Treatment</arm_group_label>
  </intervention>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Speech Production + Speech Perception Treatment.</intervention_name>
    <description>This speech treatment condition will be administered in the same way as the Speech Production treatment. The difference in conditions will be that speech treatment in this condition will last for 50 minutes rather than 60 minutes. The remaining 10 minutes of each session will involve the speech perception training. These speech perception tasks will involve previously recorded word-level productions focusing on the same phoneme that is addressed in speech production treatment in word-initial position. A variety of words produced correctly and incorrectly by adults and children will be presented in pairs and the children will have to determine if the words contain the same word-initial phoneme or two different phonemes.</description>
    <arm_group_label>Speech Treatment &amp; Perception</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion criteria (all children):

          -  Between the ages of 4;0 and 6;0 years

          -  English monolingual speakers

          -  Typical hearing abilities

          -  Typical overall development

          -  No apparent organic anomalies of the speech mechanism

          -  No global cognitive delays

          -  No receptive language impairments

        Inclusion criteria (children with speech sound disorders):

          -  Speech production abilities below the 10th percentile

          -  Exclude a minimum of 4 English consonants from sound repertoire

          -  No prior speech and/or language intervention services

          -  Prior diagnosis of speech sound disorder (SSD)

        Inclusion criteria (typically developing children):

        - All speech and language measures in the typical range

        Exclusion Criteria:

          -  Speaking a language other than (or in addition to) English

          -  Being above the age of 6 years or under 4 years
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>4 Years</minimum_age>
    <maximum_age>6 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Alycia E Cummings, Ph.D.</last_name>
    <role>Principal Investigator</role>
    <affiliation>Idaho State University - Meridian</affiliation>
  </overall_official>
  <overall_contact>
    <last_name>Alycia E Cummings, Ph.D.</last_name>
    <phone>208-373-1772</phone>
    <email>cummalyc@isu.edu</email>
  </overall_contact>
  <overall_contact_backup>
    <last_name>Brain &amp; Behavior Lab</last_name>
    <phone>208-373-1896</phone>
    <email>isubblab@isu.edu</email>
  </overall_contact_backup>
  <location>
    <facility>
      <name>Idaho State University - Meridian</name>
      <address>
        <city>Meridian</city>
        <state>Idaho</state>
        <zip>83642-7991</zip>
        <country>United States</country>
      </address>
    </facility>
    <status>Recruiting</status>
    <contact>
      <last_name>Alycia E Cummings, Ph.D.</last_name>
      <phone>208-373-1772</phone>
      <email>cummalyc@isu.edu</email>
    </contact>
    <contact_backup>
      <last_name>Brain &amp; Behavior Lab</last_name>
      <phone>208-373-1896</phone>
      <email>isubblab@isu.edu</email>
    </contact_backup>
    <investigator>
      <last_name>Alycia E Cummings, Ph.D.</last_name>
      <role>Principal Investigator</role>
    </investigator>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <verification_date>February 2019</verification_date>
  <study_first_submitted>July 23, 2018</study_first_submitted>
  <study_first_submitted_qc>August 6, 2018</study_first_submitted_qc>
  <study_first_posted type="Actual">August 9, 2018</study_first_posted>
  <last_update_submitted>February 21, 2019</last_update_submitted>
  <last_update_submitted_qc>February 21, 2019</last_update_submitted_qc>
  <last_update_posted type="Actual">February 25, 2019</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <keyword>Children</keyword>
  <keyword>Phonology</keyword>
  <keyword>EEG</keyword>
  <keyword>ERP</keyword>
  <keyword>ABR</keyword>
  <keyword>FFR</keyword>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Speech Sound Disorder</mesh_term>
  </condition_browse>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

