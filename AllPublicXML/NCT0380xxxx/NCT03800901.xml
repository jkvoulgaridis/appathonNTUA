<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on July 28, 2020</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03800901</url>
  </required_header>
  <id_info>
    <org_study_id>01-QIQ-K-2018</org_study_id>
    <nct_id>NCT03800901</nct_id>
  </id_info>
  <brief_title>Quality IQ Patient Simulation Physician Practice Measurement and Engagement</brief_title>
  <acronym>Q-IQ</acronym>
  <official_title>Quality IQ Patient Simulation Physician Practice Measurement and Engagement</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>Qure Healthcare, LLC</agency>
      <agency_class>Industry</agency_class>
    </lead_sponsor>
    <collaborator>
      <agency>CE Outcomes</agency>
      <agency_class>Other</agency_class>
    </collaborator>
  </sponsors>
  <source>Qure Healthcare, LLC</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      This study will test the quality of physician care decisions using a patient-simulation based
      measurement and feedback approach that combines multiple-choice care decisions with
      real-time, personalized scoring and feedback. The study will also measure the impact of
      gaming-inspired competition and motivation, including a weekly leaderboard, to improve
      evidence-based care decisions. In addition, the study the test the impact of CME and MOC
      credits on participant engagement in the process.
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Primary care providers (PCPs) make many of the most important care decisions, especially for
      patients with chronic conditions and multiple co-morbidities. Studies have confirmed that
      unwarranted variation is common among PCPs, with high level of variation in care documented
      between urban and rural practices, across regions, and even among providers within a single
      healthcare system.

      The investigators' previous work has shown that patient simulations can rapidly and reliably
      measure unwarranted practice variation among providers. In addition, published work shows
      that patient simulations, when administered serially and combined with customized feedback on
      improvement opportunities can reduce practice variation and improve performance on
      patient-level quality measures. Given the large scope of unwarranted variation in medical
      practice, there is a need for scalable approaches to measure care decisions, provide feedback
      on improvement opportunities and benchmark performance to peers.

      This study seeks to evaluate the impact of measurement, feedback and competition on
      evidence-based care decisions made by primary care providers across the country. It is a
      randomized, controlled trial with multiple measurements across key domains of clinical care.
      All participants are asked to care for simulated patients designed to look like typical
      patients seen in a primary care practice. In each case, providers will answer multiple-choice
      questions about their preferred course of action to work-up, diagnose and treat patients in
      the primary care setting. After each question, providers will receive evidence-based
      feedback, including references, on the appropriateness of each of their care decisions.
      Feedback will be supported with relevant reference to evidence-based guidelines, including
      national MIPS quality measures.

      All participants will receive the following interventions:

        -  Feedback on care decisions made in each Quality IQ case, which will identify correct
           care, unneeded care, or gaps in care. This feedback will recommend or reinforce
           evidence-based care decisions and includes references.

        -  All cases will be scored against evidence-based criteria. For each case, providers will
           start with 100 base points. Correct care decisions will add to that total, while
           unnecessary care decisions will subtract from that total. A weekly leaderboard will be
           posted online, allowing participants to see how they are performing relative to their
           peers across the country. Participants will have the opportunity to select a unique
           username or an anonymous user ID to be identified on the leaderboard, to maintain
           anonymity.

      Half of the recruits will be offered Category I CME credit approved by The University of
      California, San Francisco School of Medicine (UCSF) which has been accredited by the
      Accreditation Council of Continuing Medical Education to provide CME for physicians and MOC
      points in the ABIM's MOC program.
    </textblock>
  </detailed_description>
  <overall_status>Completed</overall_status>
  <start_date type="Actual">January 11, 2019</start_date>
  <completion_date type="Actual">April 15, 2019</completion_date>
  <primary_completion_date type="Actual">March 11, 2019</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>Randomized</allocation>
    <intervention_model>Parallel Assignment</intervention_model>
    <intervention_model_description>The study will enroll practicing PCPs in the US. Once eligibility is determined and providers are enrolled in the study, they will be randomized into one of two arms:
Control: will not be offered CME or ABIM MOC credits for their participation.
CME Arm: will be offered CME or ABIM MOC credits for their participation. Between the two arms, all other aspects of the study will remain constant.
All providers will then care for 1 Quality IQ patient simulation each week over the course of 6-8 weeks.</intervention_model_description>
    <primary_purpose>Health Services Research</primary_purpose>
    <masking>Single (Participant)</masking>
    <masking_description>The Control arm, who are not offered CME or ABIM MOC credits for their participation, will be unaware of the interventional CME arm. The CME arm will also be unaware of the Control arm. Per recommendations from the IRB, all participants at the end of the study will receive a study debrief letter informing them of the other study arms.</masking_description>
  </study_design_info>
  <primary_outcome>
    <measure>Change in the percentage of evidence-based diagnostic and treatment decisions made in the simulations.</measure>
    <time_frame>3 months</time_frame>
    <description>In each case, participants will answer multiple-choice questions about their preferred course of action to work-up, diagnose and treat patients in the primary care setting. Each question has specific evidence-based scoring criteria identifying necessary and unnecessary care decisions. Each provider will get a score for each case, ranging from 0 to 100 percentage based on the care decisions they make in the case. Over the course of the project, the investigators will track the percentage of correct, evidence-based care decisions made by participants, with the hypothesis that serial measurement and feedback on evidence-based care decisions will lead to increases in appropriate decisions over time. Higher scores represent a better outcome.</description>
  </primary_outcome>
  <secondary_outcome>
    <measure>Change in MIPS-relevant care decisions made in the patient simulations</measure>
    <time_frame>3 months</time_frame>
    <description>As described in the primary outcome measure, the investigators will track the percentage of evidence-based care decisions made by participants in the patient simulations. A subset of these care decisions tie directly to quality measures tracked by Medicare through the Merit-based Incentive Payment System (MIPS). For this outcome measure, the investigators will track changes in the percentage of MIPS-relevant work-up and treatment decisions made in the patient simulations. Higher scores represent a better outcome.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Change in ordering of unneeded work-up tests made in the patient simulations</measure>
    <time_frame>3 months</time_frame>
    <description>As described in the primary outcome measure, the investigators will track the percentage of evidence-based care decisions made by participants in the patient simulations. A subset of these care decisions tie to ordering of unneeded laboratory and imaging testing that is not supported by the evidence-based guidelines. For this outcome measure, the investigators will track changes in the frequency with which unneeded tests are ordered in the patient simulations. Higher scores represent a better outcome.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Participant case completion rate</measure>
    <time_frame>3 months</time_frame>
    <description>The investigators will track the percentage of enrolled participants who stay engaged in the study and complete at least 75% of their patient simulation cases.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Participant Satisfaction</measure>
    <time_frame>3 months</time_frame>
    <description>Investigators will measure participant satisfaction as measured by post-evaluation survey. On a scale of 1 to 5 (with 5 being the highest), participants will be asked about the overall quality of the material, the relevance to their practice and the educational content. Higher scores represent a better outcome.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Impact of available CME and ABIM MOC on recruitment rate</measure>
    <time_frame>3 months</time_frame>
    <description>Operating under the hypothesis that physicians offered CME and MOC credits are more likely to participate in a quality improvement program like this, the investigators will track the rate at which a randomized group of primary care physicians enroll in the program when offered CME and MOC credit and compare that to a group that is not offered CME and MOC credit for their participation.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Impact of available CME and ABIM MOC on retention rate</measure>
    <time_frame>3 months</time_frame>
    <description>Operating under the hypothesis that physicians offered CME and MOC credits are more likely to continue participating in a quality improvement program, the investigators will track the rate at which a primary care physicians eligible to earn CME and MOC credit complete the full 8 week project and compare that to a group that is not offered CME and MOC credit.</description>
  </secondary_outcome>
  <number_of_arms>2</number_of_arms>
  <enrollment type="Actual">187</enrollment>
  <condition>Diabetes</condition>
  <condition>Hypertension</condition>
  <condition>Depression</condition>
  <condition>Osteoarthritis</condition>
  <condition>Asthma</condition>
  <condition>Pain</condition>
  <condition>Heart Failure</condition>
  <arm_group>
    <arm_group_label>Control</arm_group_label>
    <arm_group_type>Active Comparator</arm_group_type>
    <description>The Control arm will be asked to care for online, Quality IQ patient simulations and will receive feedback based on their care decisions made in each case. The feedback will identify correct care, unneeded care, or gaps in care and recommend or reinforce evidence-based care decisions and includes references. This arm will not be offered Continuing Medical Education (CME) or American Board of Internal Medicine (ABIM) Part II Maintenance of Certification (MOC) credits for their participation.</description>
  </arm_group>
  <arm_group>
    <arm_group_label>CME</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>The CME arm will be asked to care for online, Quality IQ patient simulations and will receive feedback based on their care decisions made in each case. The feedback will identify correct care, unneeded care, or gaps in care and recommend or reinforce evidence-based care decisions and includes references. This arm will be offered Continuing Medical Education (CME) and American Board of Internal Medicine (ABIM) Part II Maintenance of Certification (MOC) credits for their participation.</description>
  </arm_group>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Continuing Medical Education</intervention_name>
    <description>CME or ABIM MOC credits</description>
    <arm_group_label>CME</arm_group_label>
    <other_name>CME</other_name>
  </intervention>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Quality IQ Patient Simulations</intervention_name>
    <description>Online patient cases designed to simulate typical patients seen in a primary care practice. In each case, providers will answer multiple-choice questions about their preferred course of action to work-up, diagnose and treat patients in the primary care setting. After each question, providers will receive evidence-based feedback, including references, on the appropriateness of each of their care decisions. Feedback will be supported with relevant reference to evidence-based guidelines, including national MIPS quality measures.
Cases will cover clinical conditions aligned with MIPS measures that are commonly seen in the primary care setting including: diabetes, hypertension, depression, osteoarthritis, asthma and pain control.</description>
    <arm_group_label>CME</arm_group_label>
    <arm_group_label>Control</arm_group_label>
    <other_name>Clinical Performance and Value vignettes</other_name>
    <other_name>CPVs</other_name>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:

          1. Board-certified in internal medicine or family medicine

          2. Minimum patient panel size of 1,500 patients

          3. English-speaking

          4. Access to the internet

          5. Informed, signed and voluntarily consented to be in the study

        Exclusion Criteria:

          1. Not board certified in either internal medicine or family medicine

          2. Patient panel size less than 1,500 patients

          3. Non-English speaking

          4. Unable to access the internet

          5. Does not voluntarily consent to be in the study
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>N/A</minimum_age>
    <maximum_age>N/A</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>John Peabody, MD, PhD</last_name>
    <role>Principal Investigator</role>
    <affiliation>QURE Healthcare</affiliation>
  </overall_official>
  <location>
    <facility>
      <name>QURE Healthcare</name>
      <address>
        <city>San Francisco</city>
        <state>California</state>
        <zip>94109</zip>
        <country>United States</country>
      </address>
    </facility>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <reference>
    <citation>Burgon TB, Cox-Chapman J, Czarnecki C, Kropp R, Guerriere R, Paculdo D, Peabody JW. Engaging Primary Care Providers to Reduce Unwanted Clinical Variation and Support ACO Cost and Quality Goals: A Unique Provider-Payer Collaboration. Popul Health Manag. 2019 Aug;22(4):321-329. doi: 10.1089/pop.2018.0111. Epub 2018 Oct 17.</citation>
    <PMID>30328782</PMID>
  </reference>
  <reference>
    <citation>Weigel PA, Ullrich F, Shane DM, Mueller KJ. Variation in Primary Care Service Patterns by Rural-Urban Location. J Rural Health. 2016 Spring;32(2):196-203. doi: 10.1111/jrh.12146. Epub 2015 Sep 16.</citation>
    <PMID>26376210</PMID>
  </reference>
  <reference>
    <citation>Peabody JW, Luck J, Glassman P, Dresselhaus TR, Lee M. Comparison of vignettes, standardized patients, and chart abstraction: a prospective validation study of 3 methods for measuring quality. JAMA. 2000 Apr 5;283(13):1715-22.</citation>
    <PMID>10755498</PMID>
  </reference>
  <reference>
    <citation>Peabody JW, Luck J, Glassman P, Jain S, Hansen J, Spell M, Lee M. Measuring the quality of physician practice by using clinical vignettes: a prospective validation study. Ann Intern Med. 2004 Nov 16;141(10):771-80.</citation>
    <PMID>15545677</PMID>
  </reference>
  <verification_date>March 2020</verification_date>
  <study_first_submitted>January 4, 2019</study_first_submitted>
  <study_first_submitted_qc>January 8, 2019</study_first_submitted_qc>
  <study_first_posted type="Actual">January 11, 2019</study_first_posted>
  <last_update_submitted>March 2, 2020</last_update_submitted>
  <last_update_submitted_qc>March 2, 2020</last_update_submitted_qc>
  <last_update_posted type="Actual">March 3, 2020</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Osteoarthritis</mesh_term>
    <mesh_term>Heart Failure</mesh_term>
  </condition_browse>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
    <ipd_description>No individual participant data will be shared with other researchers. Analysis will be conducted at the aggregate group level.</ipd_description>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

