<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on July 28, 2020</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT04473729</url>
  </required_header>
  <id_info>
    <org_study_id>Listening2Faces</org_study_id>
    <secondary_id>3R43DC017405-01A1S1</secondary_id>
    <nct_id>NCT04473729</nct_id>
  </id_info>
  <brief_title>Improving Perception of Speech in Noise in Children With Communication Disorders</brief_title>
  <acronym>L2F</acronym>
  <official_title>Improving Perception of Speech in Noise in Children With Communication Disorders</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>Smarty Ears</agency>
      <agency_class>Industry</agency_class>
    </lead_sponsor>
    <collaborator>
      <agency>National Institutes of Health (NIH)</agency>
      <agency_class>NIH</agency_class>
    </collaborator>
    <collaborator>
      <agency>National Institute on Deafness and Other Communication Disorders (NIDCD)</agency>
      <agency_class>NIH</agency_class>
    </collaborator>
    <collaborator>
      <agency>Southern Connecticut State University</agency>
      <agency_class>Other</agency_class>
    </collaborator>
    <collaborator>
      <agency>Haskins Laboratories</agency>
      <agency_class>Other</agency_class>
    </collaborator>
  </sponsors>
  <source>Smarty Ears</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      Smarty Ears has developed a prototype of an innovative therapeutic training system to improve
      speech perception in noise by training children on interrupted noise (which has silent
      intervals that allow for fragments of the target to be heard). The study will attempt to
      validate the technology and gather initial design feedback from clinicians and caregivers and
      from children with ASD and HL.
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Recent evidence indicates that listening in interrupted noise can provide perceptual
      benefits, such as remapping the auditory environment and learning to use acoustic cues. The
      developed technology, uses adaptive listening training that automatically increases noise
      level difficulty as performance improves, and includes age appropriate rewards to maintain
      interest. The mobile app includes an initial and final screening, a training system that
      administers training via the child's own mobile device, and detailed performance dashboard.
      The study will attempt to validate the technology by gathering feedback from clinicians and
      caregivers and from children with ASD and HL.
    </textblock>
  </detailed_description>
  <overall_status>Enrolling by invitation</overall_status>
  <start_date type="Actual">July 3, 2020</start_date>
  <completion_date type="Anticipated">February 20, 2021</completion_date>
  <primary_completion_date type="Anticipated">December 30, 2020</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>Non-Randomized</allocation>
    <intervention_model>Sequential Assignment</intervention_model>
    <intervention_model_description>The model is ABA design, that is participants get an initial, pre-treatment noise assessment, then get individualized training, then get a post-noise assessment. This is designed to look for change from baseline after training.</intervention_model_description>
    <primary_purpose>Treatment</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Daily training performance</measure>
    <time_frame>5 days a week for 4 weeks (30 minutes/day)</time_frame>
    <description>Daily performance level based on words correct as a function of SNR and the average SNR over the course of training for 4 weeks</description>
  </primary_outcome>
  <number_of_arms>3</number_of_arms>
  <enrollment type="Anticipated">30</enrollment>
  <condition>Speech Perception</condition>
  <arm_group>
    <arm_group_label>Children with an autism spectrum disorder</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>The intervention as described above with children with an ASD.</description>
  </arm_group>
  <arm_group>
    <arm_group_label>Children with Hearing Loss</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
  </arm_group>
  <arm_group>
    <arm_group_label>Typically developing children with normal hearing acuity</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
  </arm_group>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Audiovisual speech training in noise for children</intervention_name>
    <description>Children will participate in listening training in the form of an iPad app</description>
    <arm_group_label>Children with Hearing Loss</arm_group_label>
    <arm_group_label>Children with an autism spectrum disorder</arm_group_label>
    <arm_group_label>Typically developing children with normal hearing acuity</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:

          -  For all children: normal or corrected to normal vision.

          -  For children with typical development normal or corrected to normal vision + normal
             hearing.

          -  For children with HL Children must have at least one year experience with
             amplification (i.e Hearing aids) and no threshold&gt; 70 dB.

        Exclusion Criteria:

          -  To participate, all children must be able to comply with directions and engage in
             tasks that require some expressive language response on the language and cognitive
             measures (i.e. children who are considered to be in the &quot;word combinations&quot; or
             &quot;sentences expressive language&quot; phase; Tager-Flusberg et al., 2009).
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>8 Years</minimum_age>
    <maximum_age>12 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Barbara Fernandes, M.S</last_name>
    <role>Principal Investigator</role>
    <affiliation>Smarty Ears</affiliation>
  </overall_official>
  <location>
    <facility>
      <name>Southern Connecticut State University</name>
      <address>
        <city>New Haven</city>
        <state>Connecticut</state>
        <zip>06515</zip>
        <country>United States</country>
      </address>
    </facility>
  </location>
  <location>
    <facility>
      <name>Hampton University</name>
      <address>
        <city>Hampton</city>
        <state>Virginia</state>
        <zip>23669</zip>
        <country>United States</country>
      </address>
    </facility>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <link>
    <url>http://www.smartyearsapps.com</url>
    <description>Link to Small Business/PI on study</description>
  </link>
  <results_reference>
    <citation>Irwin J, Preston J, Brancazio L, D'angelo M, Turcios J. Development of an audiovisual speech perception app for children with autism spectrum disorders. Clin Linguist Phon. 2015 Jan;29(1):76-83. doi: 10.3109/02699206.2014.966395. Epub 2014 Oct 14.</citation>
    <PMID>25313714</PMID>
  </results_reference>
  <results_reference>
    <citation>Irwin JR, Tornatore LA, Brancazio L, Whalen DH. Can children with autism spectrum disorders &quot;hear&quot; a speaking face? Child Dev. 2011 Sep-Oct;82(5):1397-403. doi: 10.1111/j.1467-8624.2011.01619.x. Epub 2011 Jul 25.</citation>
    <PMID>21790542</PMID>
  </results_reference>
  <results_reference>
    <citation>Irwin JR, Brancazio L. Seeing to hear? Patterns of gaze to speaking faces in children with autism spectrum disorders. Front Psychol. 2014 May 8;5:397. doi: 10.3389/fpsyg.2014.00397. eCollection 2014.</citation>
    <PMID>24847297</PMID>
  </results_reference>
  <verification_date>July 2020</verification_date>
  <study_first_submitted>July 13, 2020</study_first_submitted>
  <study_first_submitted_qc>July 13, 2020</study_first_submitted_qc>
  <study_first_posted type="Actual">July 16, 2020</study_first_posted>
  <last_update_submitted>July 13, 2020</last_update_submitted>
  <last_update_submitted_qc>July 13, 2020</last_update_submitted_qc>
  <last_update_posted type="Actual">July 16, 2020</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <keyword>ASD</keyword>
  <keyword>speech in noise</keyword>
  <keyword>Hearing Loss</keyword>
  <keyword>speech-to-noise ratio</keyword>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Communication Disorders</mesh_term>
  </condition_browse>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

