<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on July 28, 2020</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03640130</url>
  </required_header>
  <id_info>
    <org_study_id>STUDY00001096</org_study_id>
    <nct_id>NCT03640130</nct_id>
  </id_info>
  <brief_title>Peripheral Reading</brief_title>
  <official_title>Factors Limiting Peripheral Reading</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>University of Houston</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>University of Houston</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      The purpose of this study is to evaluate reading performance in the visual periphery by
      simulating central vision loss using a computer-controlled gaze-contingent display with an
      eye tracker. Participants will read a page of text at a comfortable rate. Several
      manipulations hypothesized to improve reading will be tested, such as an inverted-text
      &quot;spotlight&quot; of a single word that follows the participant's gaze.
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Participants will view paragraphs of multiple sentences of text with their central vision
      blocked computationally with a &quot;simulated scotoma.&quot; Participants will be free to move their
      eyes around the page of text at a comfortable rate. The three outcomes described elsewhere
      will be evaluated.

      In different blocks, text will contain one or more of several dynamic assistive manipulations
      that are hypothesized to enhance reading: 1) inverting the text at a given position, with
      instructions for the participant to attend to that location, which simulates a &quot;surrogate
      fovea&quot; of a patient with central vision loss. 2) horizontally expanding text to alleviate
      within-word crowding. 3) highlighting the next word with a visible indicator to encourage
      proper eye movements.
    </textblock>
  </detailed_description>
  <overall_status>Enrolling by invitation</overall_status>
  <start_date type="Actual">November 1, 2018</start_date>
  <completion_date type="Anticipated">March 1, 2019</completion_date>
  <primary_completion_date type="Anticipated">March 1, 2019</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>N/A</allocation>
    <intervention_model>Single Group Assignment</intervention_model>
    <primary_purpose>Other</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Reading speed</measure>
    <time_frame>From enrollment to completion of testing (&lt;2 weeks)</time_frame>
    <description>Average time/word it takes to read a paragraph of text.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Reading accuracy</measure>
    <time_frame>From enrollment to completion of testing (&lt;2 weeks)</time_frame>
    <description>Ability to correctly answer comprehension questions or orally read words</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Efficiency of eye movement</measure>
    <time_frame>From enrollment to completion of testing (&lt;2 weeks)</time_frame>
    <description>Ability to move the eyes systematically from word to word</description>
  </primary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Anticipated">6</enrollment>
  <condition>Central Visual Impairment</condition>
  <arm_group>
    <arm_group_label>Single Arm</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>Each participant will participate in several blocks (randomized order), to evaluate performance with and without behavioral gaze-contingent text enhancements.</description>
  </arm_group>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Gaze-contingent text enhancement</intervention_name>
    <description>In different testing blocks, the efficacy of the different enhancements will be evaluated, such as inverting the text in a gaze-contingent inverted &quot;spotlight.&quot;</description>
    <arm_group_label>Single Arm</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:

          -  Normal vision

          -  English language

        Exclusion Criteria:

          -  Less than 20/20 vision in either eye

          -  Abnormalities which affect vision (amblyopia, keratoconus, etc.)

          -  Ortho-K lenses
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>N/A</minimum_age>
    <maximum_age>N/A</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <location>
    <facility>
      <name>University of Houston, College of Optometry</name>
      <address>
        <city>Houston</city>
        <state>Texas</state>
        <zip>77204</zip>
        <country>United States</country>
      </address>
    </facility>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <verification_date>November 2018</verification_date>
  <study_first_submitted>August 19, 2018</study_first_submitted>
  <study_first_submitted_qc>August 19, 2018</study_first_submitted_qc>
  <study_first_posted type="Actual">August 21, 2018</study_first_posted>
  <last_update_submitted>November 13, 2018</last_update_submitted>
  <last_update_submitted_qc>November 13, 2018</last_update_submitted_qc>
  <last_update_posted type="Actual">November 14, 2018</last_update_posted>
  <responsible_party>
    <responsible_party_type>Principal Investigator</responsible_party_type>
    <investigator_affiliation>University of Houston</investigator_affiliation>
    <investigator_full_name>Daniel R. Coates</investigator_full_name>
    <investigator_title>Assistant Professor</investigator_title>
  </responsible_party>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Vision Disorders</mesh_term>
    <mesh_term>Vision, Low</mesh_term>
  </condition_browse>
  <patient_data>
    <sharing_ipd>Undecided</sharing_ipd>
    <ipd_description>To conform with open science directives, will likely post the de-identified behavioral data on a public server.</ipd_description>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

